{"cells":[{"cell_type":"markdown","metadata":{"id":"b3D6Ar4HZTsY"},"source":["# Text Processing and Word Embeddings\n","\n","Welcome to this new exercise! In this exercise, we will play around with text instead of images as before, using Recurrent Neural Networks. Generally, it is called Natural Language Processing (NLP) when dealing with text, speech, etc. But the data structure is very different from images, i.e., text is a string, while images consist of numbers. Hence, we need some preprocessing steps to transform the raw text into another data format. This notebook will introduce these basic concepts in NLP pipelines. Specifically, you will learn about:\n","\n","1. How to preprocess text classification datasets\n","2. How to create a simple word embedding layer that maps words to dense vectors"]},{"cell_type":"markdown","metadata":{"id":"mnkMlyK_ZTsj"},"source":["## (Optional) Mount folder in Colab\n","\n","Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3688,"status":"ok","timestamp":1658350753184,"user":{"displayName":"Berfin Kavşut","userId":"14341270727018230240"},"user_tz":-120},"id":"lb0d1qB-ZTsl","outputId":"65878d47-e2b9-4d99-802c-c602f2dc2cac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n","['.ipynb_checkpoints', '1_text_preprocessing_and_embedding.ipynb', '2_sentiment_analysis.ipynb', 'Optional-recurrent_neural_networks.ipynb', 'exercise_code', 'images', 'models']\n"]}],"source":["# Use the following lines if you want to use Google Colab\n","# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n","# NOTE: terminate all other colab sessions that use GPU!\n","# NOTE 2: Make sure the correct exercise folder (e.g exercise_11) is given.\n","\n","\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/SoSe\\'22/i2dl/exercise_11'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))\n"]},{"cell_type":"markdown","metadata":{"id":"6R-s48U7ZTsp"},"source":["### Set up PyTorch environment in colab\n","- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n","- Uncomment the following cell if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1658350753185,"user":{"displayName":"Berfin Kavşut","userId":"14341270727018230240"},"user_tz":-120},"id":"a-Kh5C2Kcmh6","outputId":"2984352f-d1ab-484c-cd5f-fad9f01b112c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Jul 20 22:59:11 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"lFINw5q1ZTsq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n","\u001b[K     |████████████████▎               | 834.1 MB 3.5 MB/s eta 0:03:52tcmalloc: large alloc 1147494400 bytes == 0x39b14000 @  0x7f1f92383615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████▋           | 1055.7 MB 1.2 MB/s eta 0:07:56tcmalloc: large alloc 1434370048 bytes == 0x7e16a000 @  0x7f1f92383615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▏     | 1336.2 MB 1.2 MB/s eta 0:04:04tcmalloc: large alloc 1792966656 bytes == 0x2f9c000 @  0x7f1f92383615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 1636.9 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1636958208 bytes == 0x6dd84000 @  0x7f1f923821e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2046197760 bytes == 0xcf6a4000 @  0x7f1f92383615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 1637.0 MB 6.6 kB/s \n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 34.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.0+cu113\n","    Uninstalling torchvision-0.13.0+cu113:\n","      Successfully uninstalled torchvision-0.13.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.11.0+cu113 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\n","Successfully installed torch-1.11.0+cu113 torchvision-0.12.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboard==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (3.4.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (3.17.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (57.4.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.21.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (1.47.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8.0) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (4.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.8.0) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.8.0) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.8.0) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (3.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning==1.6.0\n","  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n","\u001b[K     |████████████████████████████████| 582 kB 8.0 MB/s \n","\u001b[?25hCollecting PyYAML>=5.4\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.8 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 77.4 MB/s \n","\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (1.11.0+cu113)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (2.8.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (4.1.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (21.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (4.64.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 58.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.0) (3.0.9)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.47.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (57.4.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.17.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (21.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 22.7 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.1.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 79.8 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.9.2 yarl-1.7.2\n"]}],"source":["# Optional: install correct libraries in google colab\n","!python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n","!python -m pip install tensorboard==2.8.0\n","!python -m pip install pytorch-lightning==1.6.0"]},{"cell_type":"markdown","metadata":{"id":"TBPLZMOpZTsr"},"source":["# 0. Setup\n","\n","As usual, we first import some packages to setup this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VqHmZwfQZTst"},"outputs":[],"source":["import os\n","import torch\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","\n","from exercise_code.rnn.sentiment_dataset import (\n","    create_dummy_data,\n","    download_data\n",")\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"UWm5AQaLZTsv"},"source":["# 1. Preprocessing a Text Classification Dataset\n","\n","As a starting point, let's load a dummy text classification dataset and have a sense of how it looks. We take these samples from the IMDb movie review dataset, which includes movie reviews and labels that show whether they are negative (0) or positive (1). You will investigate this task further in the second notebook.\n","\n","In this section, our goal is to create a text processing dataset. You are not required to write any code in this section. However, the concept introduced here is very important for working on NLP datasets in the future as well as in the rest of this exercise. \n","Take your time to understand the procedure here. \n","\n","First, let us download the data and take a look at some data samples."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qWYJMdBbZTsx"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text: Obviously written for the stage. Lightweight but worthwhile. How can you go wrong with Ralph Richardson, Olivier and Merle Oberon.\n","Label: 1\n","\n","Text: Adrian Pasdar is excellent is this film. He makes a fascinating woman.\n","Label: 1\n","\n","Text: Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n","Label: 1\n","\n","Text: Long, boring, blasphemous. Never have I been so glad to see ending credits roll.\n","Label: 0\n","\n","Text: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n","Label: 0\n","\n","Text: A rating of \"1\" does not begin to express how dull, depressing and relentlessly bad this movie is.\n","Label: 0\n","\n"]}],"source":["i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n","data_root = os.path.join(i2dl_exercises_path, \"datasets\", \"SentimentData\")\n","path = download_data(data_root)\n","data = create_dummy_data(path)\n","for text, label in data:\n","    print('Text: {}'.format(text))\n","    print('Label: {}'.format(label))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"gASOtvTkZTsz"},"source":["## 1.1 Tokenizing Data\n","\n","As seen above, we loaded 3 positive and 3 negative reviews. Since the basic semantic unit of text is a word, the first thing we need to do is **tokenizing** the dataset, which means converting each review to a list of words."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HVPbxI6PZTs1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(['obviously', 'written', 'for', 'the', 'stage', 'lightweight', 'but', 'worthwhile', 'how', 'can', 'you', 'go', 'wrong', 'with', 'ralph', 'richardson', 'olivier', 'and', 'merle', 'oberon'], 1) \n","\n","(['adrian', 'pasdar', 'is', 'excellent', 'is', 'this', 'film', 'he', 'makes', 'a', 'fascinating', 'woman'], 1) \n","\n","(['smallville', 'episode', 'justice', 'is', 'the', 'best', 'episode', 'of', 'smallville', 'it', 's', 'my', 'favorite', 'episode', 'of', 'smallville'], 1) \n","\n","(['long', 'boring', 'blasphemous', 'never', 'have', 'i', 'been', 'so', 'glad', 'to', 'see', 'ending', 'credits', 'roll'], 0) \n","\n","(['no', 'comment', 'stupid', 'movie', 'acting', 'average', 'or', 'worse', 'screenplay', 'no', 'sense', 'at', 'all', 'skip', 'it'], 0) \n","\n","(['a', 'rating', 'of', '1', 'does', 'not', 'begin', 'to', 'express', 'how', 'dull', 'depressing', 'and', 'relentlessly', 'bad', 'this', 'movie', 'is'], 0) \n","\n"]}],"source":["import re\n","\n","# use regular expression to split the sentence\n","# check https://docs.python.org/3/library/re.html for more information\n","def tokenize(text):\n","    return [s.lower() for s in re.split(r'\\W+', text) if len(s) > 0]\n","\n","tokenized_data = []\n","for text, label in data:\n","    tokenized_data.append((tokenize(text), label))\n","    print(tokenized_data[-1], '\\n')"]},{"cell_type":"markdown","metadata":{"id":"QsSBm4dnZTs2"},"source":["## 1.2 Creating a Vocabulary\n","\n","We have converted the dataset into pairs of token lists and corresponding labels. But strings have varying lengths, which is hard to handle. It would be nice to represent words with numbers. So, we need to create a <b>vocabulary</b>, which is a dictionary that maps each word to an integer id.\n","\n","In large datasets, there are too many words, and most of them don't occur very frequently. One common approach we use to tackle this problem is to pick the most common N words from the dataset. Therefore, we restrict the number of words.\n","\n","First, let's compute the word frequencies in our dummy dataset. To compute frequencies, we use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) data structure."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LEmM_wvQZTs3"},"outputs":[{"data":{"text/plain":["Counter({'1': 1,\n","         'a': 2,\n","         'acting': 1,\n","         'adrian': 1,\n","         'all': 1,\n","         'and': 2,\n","         'at': 1,\n","         'average': 1,\n","         'bad': 1,\n","         'been': 1,\n","         'begin': 1,\n","         'best': 1,\n","         'blasphemous': 1,\n","         'boring': 1,\n","         'but': 1,\n","         'can': 1,\n","         'comment': 1,\n","         'credits': 1,\n","         'depressing': 1,\n","         'does': 1,\n","         'dull': 1,\n","         'ending': 1,\n","         'episode': 3,\n","         'excellent': 1,\n","         'express': 1,\n","         'fascinating': 1,\n","         'favorite': 1,\n","         'film': 1,\n","         'for': 1,\n","         'glad': 1,\n","         'go': 1,\n","         'have': 1,\n","         'he': 1,\n","         'how': 2,\n","         'i': 1,\n","         'is': 4,\n","         'it': 2,\n","         'justice': 1,\n","         'lightweight': 1,\n","         'long': 1,\n","         'makes': 1,\n","         'merle': 1,\n","         'movie': 2,\n","         'my': 1,\n","         'never': 1,\n","         'no': 2,\n","         'not': 1,\n","         'oberon': 1,\n","         'obviously': 1,\n","         'of': 3,\n","         'olivier': 1,\n","         'or': 1,\n","         'pasdar': 1,\n","         'ralph': 1,\n","         'rating': 1,\n","         'relentlessly': 1,\n","         'richardson': 1,\n","         'roll': 1,\n","         's': 1,\n","         'screenplay': 1,\n","         'see': 1,\n","         'sense': 1,\n","         'skip': 1,\n","         'smallville': 3,\n","         'so': 1,\n","         'stage': 1,\n","         'stupid': 1,\n","         'the': 2,\n","         'this': 2,\n","         'to': 2,\n","         'with': 1,\n","         'woman': 1,\n","         'worse': 1,\n","         'worthwhile': 1,\n","         'written': 1,\n","         'wrong': 1,\n","         'you': 1})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from collections import Counter\n","\n","freqs = Counter()\n","for tokens, _ in tokenized_data:\n","    freqs.update(tokens)\n","\n","freqs"]},{"cell_type":"markdown","metadata":{"id":"MhAzXslbZTs4"},"source":["To create the dictionary, let's select the most common 20 words to create a vocabulary. In addition to the words that appear in our data, we need to have two special words:\n","\n","- `<eos>` End of sequence symbol used for padding\n","- `<unk>` Words unknown in our vocabulary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uH6lPE_DZTs5"},"outputs":[{"data":{"text/plain":["{'<eos>': 0,\n"," '<unk>': 1,\n"," 'a': 10,\n"," 'and': 8,\n"," 'but': 20,\n"," 'episode': 4,\n"," 'for': 17,\n"," 'how': 7,\n"," 'is': 2,\n"," 'it': 11,\n"," 'lightweight': 19,\n"," 'movie': 14,\n"," 'no': 13,\n"," 'obviously': 15,\n"," 'of': 5,\n"," 'smallville': 3,\n"," 'stage': 18,\n"," 'the': 6,\n"," 'this': 9,\n"," 'to': 12,\n"," 'worthwhile': 21,\n"," 'written': 16}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["vocab = {'<eos>': 0, '<unk>': 1}\n","for token, freq in freqs.most_common(20):\n","    vocab[token] = len(vocab)\n","vocab"]},{"cell_type":"markdown","metadata":{"id":"IuiQ-r2KZTs6"},"source":["## 1.3 Creating the Dataset\n","\n","Putting it all together, we can now create a dataset class. First, let's create index-label pairs:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Bf5NJ0GBZTs6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[15, 16, 17, 6, 18, 19, 20, 21, 7, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1]  ->  1\n","\n","[1, 1, 2, 1, 2, 9, 1, 1, 1, 10, 1, 1]  ->  1\n","\n","[3, 4, 1, 2, 6, 1, 4, 5, 3, 11, 1, 1, 1, 4, 5, 3]  ->  1\n","\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 12, 1, 1, 1, 1]  ->  0\n","\n","[13, 1, 1, 14, 1, 1, 1, 1, 1, 13, 1, 1, 1, 1, 11]  ->  0\n","\n","[10, 1, 5, 1, 1, 1, 1, 12, 1, 7, 1, 1, 8, 1, 1, 9, 14, 2]  ->  0\n","\n"]}],"source":["indexed_data = []\n","for tokens, label in tokenized_data:\n","    indices = [vocab.get(token, vocab['<unk>']) for token in tokens]    \n","    # the token that is not in vocab get assigned <unk>\n","    indexed_data.append((indices, label))\n","    \n","\n","for indices, label in indexed_data:\n","    print(indices, ' -> ', label)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"1ffvMPyKZTs7"},"source":["<div class=\"alert alert-success\"> \n","    <h3>Task: Check Code</h3>\n","    <p>We now use the PyTorch dataset class we provided in <code>exercise_code/rnn/sentiment_dataset.py</code> file. Please also take a look at the code.</p>\n"," </div>\n","    \n","\n","\n","Dataset class also reverse sorts the sequences with respect to the lengths. Thanks to this sorting, we can reduce the total number of padded elements, which means that we have less computations for padded values."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MWh7Hy6aZTs9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'data': tensor([15, 16, 17,  6, 18, 19, 20, 21,  7,  1,  1,  1,  1,  1,  1,  1,  1,  8,\n","         1,  1]), 'label': tensor(1.)}\n","\n","{'data': tensor([10,  1,  5,  1,  1,  1,  1, 12,  1,  7,  1,  1,  8,  1,  1,  9, 14,  2]), 'label': tensor(0.)}\n","\n","{'data': tensor([ 3,  4,  1,  2,  6,  1,  4,  5,  3, 11,  1,  1,  1,  4,  5,  3]), 'label': tensor(1.)}\n","\n","{'data': tensor([13,  1,  1, 14,  1,  1,  1,  1,  1, 13,  1,  1,  1,  1, 11]), 'label': tensor(0.)}\n","\n","{'data': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1]), 'label': tensor(0.)}\n","\n","{'data': tensor([ 1,  1,  2,  1,  2,  9,  1,  1,  1, 10,  1,  1]), 'label': tensor(1.)}\n","\n"]}],"source":["from exercise_code.rnn.sentiment_dataset import SentimentDataset\n","\n","combined_data = [\n","    (raw_text, tokens, indices, label)\n","    for (raw_text, label), (tokens, _), (indices, _)\n","    in zip(data, tokenized_data, indexed_data)\n","]\n","\n","dataset = SentimentDataset(combined_data)\n","\n","for elem in dataset:\n","    print(elem)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"LyOR27xpZTs-"},"source":["## 1.4 Minibatching\n","Note that in the dataset we created, not all sequences have the same length. Therefore, we cannot minibatch the data trivially. This means we cannot use a `DataLoader` class easily.\n","\n","<b>If you uncomment the following cell and run it, you will very likely get an error!</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SNajBMLMZTs_"},"outputs":[],"source":["# loader = DataLoader(dataset, batch_size=3)\n","\n","# for batch in loader:\n","#     print(batch)"]},{"cell_type":"markdown","metadata":{"id":"zbHg_vxhZTtA"},"source":["<div class=\"alert alert-success\"> \n","    <h3>Task: Check Code</h3>\n","    <p>To solve the problem, we need to pad the sequences with <code> < eos > </code> tokens that we indexed as zero. To integrate this approach into the Pytorch <a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\" target=\"_blank\">Dataloader</a> class, we will make use of the <code>collate_fn</code> argument. For more details, check out the <code>collate</code> function in <code>exercise_code/rnn/sentiment_dataset</code>. </p>\n","    <p> In addition, we use the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html\" target=\"_blank\">pad_sequence</a> that pads shorter sequences with 0. </p>\n"," </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_BX5D0-7ZTtA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data: \n"," tensor([[15, 10,  3],\n","        [16,  1,  4],\n","        [17,  5,  1],\n","        [ 6,  1,  2],\n","        [18,  1,  6],\n","        [19,  1,  1],\n","        [20,  1,  4],\n","        [21, 12,  5],\n","        [ 7,  1,  3],\n","        [ 1,  7, 11],\n","        [ 1,  1,  1],\n","        [ 1,  1,  1],\n","        [ 1,  8,  1],\n","        [ 1,  1,  4],\n","        [ 1,  1,  5],\n","        [ 1,  9,  3],\n","        [ 1, 14,  0],\n","        [ 8,  2,  0],\n","        [ 1,  0,  0],\n","        [ 1,  0,  0]])\n","\n","Labels: \n"," tensor([1., 0., 1.])\n","\n","Sequence Lengths: \n"," tensor([20, 18, 16])\n","\n","\n","Data: \n"," tensor([[13,  1,  1],\n","        [ 1,  1,  1],\n","        [ 1,  1,  2],\n","        [14,  1,  1],\n","        [ 1,  1,  2],\n","        [ 1,  1,  9],\n","        [ 1,  1,  1],\n","        [ 1,  1,  1],\n","        [ 1,  1,  1],\n","        [13, 12, 10],\n","        [ 1,  1,  1],\n","        [ 1,  1,  1],\n","        [ 1,  1,  0],\n","        [ 1,  1,  0],\n","        [11,  0,  0]])\n","\n","Labels: \n"," tensor([0., 0., 1.])\n","\n","Sequence Lengths: \n"," tensor([15, 14, 12])\n","\n","\n"]}],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","def collate(batch):\n","    assert isinstance(batch, list)\n","    data = pad_sequence([b['data'] for b in batch])\n","    lengths = torch.tensor([len(b['data']) for b in batch])\n","    label = torch.stack([b['label'] for b in batch])\n","    return {\n","        'data': data,\n","        'label': label,\n","        'lengths': lengths\n","    }\n","\n","loader = DataLoader(dataset, batch_size=3, collate_fn=collate)\n","for batch in loader:\n","    print('Data: \\n', batch['data'])\n","    print('\\nLabels: \\n', batch['label'])\n","    print('\\nSequence Lengths: \\n', batch['lengths'])\n","    print('\\n')"]},{"cell_type":"markdown","metadata":{"id":"w_c-q7POZTtC"},"source":["We can see that these two batches have different length, this is how the reverse sort mentioned in `1.3 Creating the Dataset` benefits for less memory and less computation. "]},{"cell_type":"markdown","metadata":{"id":"w-0reSl7ZTtC"},"source":["# 2. Embeddings\n","\n","In the previous section, we explored how to convert text into a sequence of integers. In this form, sequences are still not ready to be inputs of RNNs you implemented in the optional notebook. \n","\n","An integer representation is usually a one-hot encoding, while not the same since they are not equally weighted given only an integer. \n","\n","Moreover, it fails to express the semantic relations between words and the order of the words has no meaning. We would like a better representation to keep the semantic meaning of the word. For example, as shown in the following picture, the difference between man and woman and the difference between king and queen should be close, since the difference is only the gender. If we use a vector for each word, the above relation can be expressed as $vec(\\text{women})-vec(\\text{man}) \\approx vec(\\text{queen}) - vec(\\text{king})$. Usually we call such vector representations as embeddings.\n","\n","<img src='https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg' width=80% height=80%/>\n","\n","While one can use pre-trained embedding vectors such as [word2vec](https://arxiv.org/abs/1301.3781) or [GLoVe](https://nlp.stanford.edu/projects/glove/), in this exercise we use randomly initialized embedding vectors that will be trained from scratch together with our networks. As we train our model, it will learn the semantic relations between words."]},{"cell_type":"markdown","metadata":{"id":"DLsRf6XjZTtD"},"source":["<div class=\"alert alert-info\">\n","\n","<h3> Task: Implement Embedding</h3>\n"," <p>In this part, you will implement a simple embedding layer. Embedding is a simple lookup table that stores a dense vector to represent each word in the vocabulary.</p> \n","\n"," <p>Your task is to implement the <code>Embedding</code> class in <code>exercise_code.rnn.rnn_nn</code> file. Once you are done, run the below cell to test your implementation. Note that we ensure eos embeddings to be zero by using the <code>padding_idx</code> argument.\n","\n"," </div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtzZOGvAwcxt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658265407321,"user":{"displayName":"Berfin Kavşut","userId":"14341270727018230240"},"user_tz":-120},"id":"Pa5T0foyZTtD","outputId":"bf467d69-2771-4bae-faaf-8ab2cc51ebd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Difference between outputs: 0.0\n","Test passed :)!\n"]},{"data":{"text/plain":["True"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import torch.nn as nn\n","\n","from exercise_code.rnn.rnn_nn import Embedding\n","from exercise_code.rnn.tests import embedding_output_test\n","\n","\n","i2dl_embedding = Embedding(len(vocab), 16, padding_idx=0)\n","pytorch_embedding = nn.Embedding(len(vocab), 16, padding_idx=0)\n","\n","loader = DataLoader(dataset, batch_size=len(dataset), collate_fn=collate)\n","for batch in loader:\n","    x = batch['data']\n","\n","embedding_output_test(i2dl_embedding, pytorch_embedding, x)\n"]},{"cell_type":"markdown","metadata":{"id":"YX0ZemjPZTtD"},"source":["# 3. Conclusion\n","\n","In this notebook, you learned how to prepare text data and how to create an embedding layer. In the next notebook, you will combine your Embedding and RNN implementations to create a sentiment analysis network!"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"1_text_preprocessing_and_embedding.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
